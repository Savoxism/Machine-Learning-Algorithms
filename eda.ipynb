{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8691e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547a99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"data/amazon_elec_500k/train_ratings.csv\")\n",
    "test_raw = pd.read_csv(\"data/amazon_elec_500k/test_ratings.csv\")\n",
    "\n",
    "print(f\"Train dataset shape: {train_raw.shape}\")\n",
    "print(f\"Test dataset shape: {test_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b19753",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train_raw[['user_id', 'item_id', 'rating']].copy()\n",
    "test_subset = test_raw[['user_id', 'item_id', 'rating']].copy()\n",
    "\n",
    "print(f\"Train subset shape: {train_subset.shape}\")\n",
    "print(f\"Test subset shape: {test_subset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16996972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and test data\n",
    "merged_ratings = pd.concat([train_subset, test_subset], ignore_index=True)\n",
    "\n",
    "print(f\"Merged dataset shape: {merged_ratings.shape}\")\n",
    "print(f\"Unique users: {merged_ratings['user_id'].nunique()}\")\n",
    "print(f\"Unique items: {merged_ratings['item_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f23cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates across train and test\n",
    "duplicate_mask = merged_ratings.duplicated(subset=['user_id', 'item_id'], keep=False)\n",
    "duplicates = merged_ratings[duplicate_mask]\n",
    "\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"Found {len(duplicates)} duplicate user-item pairs\")\n",
    "    # Count how many are in both train and test\n",
    "    dup_groups = duplicates.groupby(['user_id', 'item_id'])\n",
    "    cross_set_dups = sum(1 for _, group in dup_groups if len(group['source'].unique()) > 1)\n",
    "    print(f\"User-item pairs in both train and test: {cross_set_dups}\")\n",
    "else:\n",
    "    print(\"No duplicates found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce61d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ratings.to_csv(\"data/amazon_elec_500k/ratings.csv\", index=False)\n",
    "print(f\"Saved merged ratings to ratings.csv with {len(merged_ratings)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd885c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert merged_ratings['user_id'].notna().all(), \"Missing user IDs found\"\n",
    "assert merged_ratings['item_id'].notna().all(), \"Missing item IDs found\"\n",
    "assert merged_ratings['rating'].notna().all(), \"Missing ratings found\"\n",
    "assert merged_ratings['rating'].between(1, 5).all(), \"Rating values outside expected range (1-5)\"\n",
    "assert len(merged_ratings) == len(train_subset) + len(test_subset), \"Row count mismatch after merging\"\n",
    "print(\"Data integrity checks passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e9406",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c217a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "ratings = pd.read_csv(\"data/amazon_elec_500k/ratings.csv\")\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f94e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique users: {ratings['user_id'].nunique()}\")\n",
    "print(f\"Unique items: {ratings['item_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute interactions per user and item\n",
    "user_counts = ratings['user_id'].value_counts()\n",
    "item_counts = ratings['item_id'].value_counts()\n",
    "\n",
    "print(f\"Interactions per user (mean): {user_counts.mean():.2f}\")\n",
    "print(f\"Interactions per user (median): {user_counts.median():.2f}\")\n",
    "print(f\"Interactions per user (min): {user_counts.min()}\")\n",
    "print(f\"Interactions per user (max): {user_counts.max()}\")\n",
    "\n",
    "print(f\"Interactions per item (mean): {item_counts.mean():.2f}\")\n",
    "print(f\"Interactions per item (median): {item_counts.median():.2f}\")\n",
    "print(f\"Interactions per item (min): {item_counts.min()}\")\n",
    "print(f\"Interactions per item (max): {item_counts.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857237f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate utility matrix density\n",
    "n_users = ratings['user_id'].nunique()\n",
    "n_items = ratings['item_id'].nunique()\n",
    "n_possible_interactions = n_users * n_items\n",
    "n_actual_interactions = len(ratings)\n",
    "\n",
    "density = n_actual_interactions / n_possible_interactions\n",
    "print(f\"Utility matrix density: {density:.6f} ({density*100:.4f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average ratings\n",
    "avg_rating_per_user = ratings.groupby('user_id')['rating'].mean()\n",
    "avg_rating_per_item = ratings.groupby('item_id')['rating'].mean()\n",
    "\n",
    "print(f\"Average rating per user (mean): {avg_rating_per_user.mean():.2f}\")\n",
    "print(f\"Average rating per user (std): {avg_rating_per_user.std():.2f}\")\n",
    "print(f\"Average rating per user (min): {avg_rating_per_user.min():.2f}\")\n",
    "print(f\"Average rating per user (max): {avg_rating_per_user.max():.2f}\")\n",
    "\n",
    "print(f\"Average rating per item (mean): {avg_rating_per_item.mean():.2f}\")\n",
    "print(f\"Average rating per item (std): {avg_rating_per_item.std():.2f}\")\n",
    "print(f\"Average rating per item (min): {avg_rating_per_item.min():.2f}\")\n",
    "print(f\"Average rating per item (max): {avg_rating_per_item.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze distribution of ratings\n",
    "rating_counts = ratings['rating'].value_counts().sort_index()\n",
    "print(\"Rating distribution:\")\n",
    "for rating, count in rating_counts.items():\n",
    "    percentage = count / len(ratings) * 100\n",
    "    print(f\"Rating {rating}: {count} ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a047c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify users and items with few interactions\n",
    "low_activity_users = user_counts[user_counts < 5].count()\n",
    "low_activity_items = item_counts[item_counts < 5].count()\n",
    "\n",
    "print(f\"Users with less than 5 ratings: {low_activity_users} ({low_activity_users/n_users*100:.2f}%)\")\n",
    "print(f\"Items with less than 5 ratings: {low_activity_items} ({low_activity_items/n_items*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for potential cold start issues\n",
    "single_interaction_users = user_counts[user_counts == 1].count()\n",
    "single_interaction_items = item_counts[item_counts == 1].count()\n",
    "\n",
    "print(f\"Users with exactly 1 rating: {single_interaction_users} ({single_interaction_users/n_users*100:.2f}%)\")\n",
    "print(f\"Items with exactly 1 rating: {single_interaction_items} ({single_interaction_items/n_items*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert statements to check data integrity\n",
    "assert ratings['user_id'].notna().all(), \"Missing user IDs found\"\n",
    "assert ratings['item_id'].notna().all(), \"Missing item IDs found\"\n",
    "assert ratings['rating'].notna().all(), \"Missing ratings found\"\n",
    "assert ratings['rating'].between(1, 5).all(), \"Rating values outside expected range (1-5)\"\n",
    "assert n_users > 0, \"No users found in dataset\"\n",
    "assert n_items > 0, \"No items found in dataset\"\n",
    "assert len(ratings) == n_actual_interactions, \"Interaction count mismatch\"\n",
    "assert avg_rating_per_user.between(1, 5).all(), \"Invalid user average ratings\"\n",
    "assert avg_rating_per_item.between(1, 5).all(), \"Invalid item average ratings\"\n",
    "print(\"All data integrity checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae9bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = ratings['user_id'].unique()\n",
    "unique_items = ratings['item_id'].unique()\n",
    "\n",
    "user_id_map = {old_id: new_id for new_id, old_id in enumerate(unique_users)}\n",
    "item_id_map = {old_id: new_id for new_id, old_id in enumerate(unique_items)}\n",
    "\n",
    "print(f\"Number of unique users: {len(user_id_map)}\")\n",
    "print(f\"Number of unique items: {len(item_id_map)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a246da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mapping to create new columns\n",
    "ratings['user_idx'] = ratings['user_id'].map(user_id_map)\n",
    "ratings['item_idx'] = ratings['item_id'].map(item_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a47881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by user_idx\n",
    "mapped_ratings = ratings.sort_values(by='user_idx').reset_index(drop=True)\n",
    "\n",
    "# Select only the necessary columns\n",
    "mapped_ratings = mapped_ratings[['user_idx', 'item_idx', 'rating']]\n",
    "\n",
    "print(f\"Mapped ratings shape: {mapped_ratings.shape}\")\n",
    "mapped_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867aaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_ratings.to_csv(\"data/amazon_elec_500k/cleaned_ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926be62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
