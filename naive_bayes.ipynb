{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVMl/uj9lKyKtXm2P9Q8Zl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Savoxism/Mathematical-Algorithms/blob/main/naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup, importing neccesary modules\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "YeEZLUddpjMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import string"
      ],
      "metadata": {
        "id": "5t2sI7j2X2PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the dataset\n",
        "dataframe_emails = pd.read_csv('emails.csv')\n",
        "dataframe_emails.head()"
      ],
      "metadata": {
        "id": "SWVtijXsoUl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of emails: {len(dataframe_emails)}\")\n",
        "print(f\"Proportion of spam emails: {dataframe_emails.spam.sum()/len(dataframe_emails):.4f}\")\n",
        "print(f\"Proportion of ham emails: {1-dataframe_emails.spam.sum()/len(dataframe_emails):.4f}\")"
      ],
      "metadata": {
        "id": "vGPrfr-cokXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleansing the data\n",
        "def preprocess_emails(df):\n",
        "    \"\"\"\n",
        "    Preprocesses email data from a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pandas.DataFrame): The input DataFrame containing email data with 'text' and 'spam' columns.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: A tuple containing two elements:\n",
        "        1. X (numpy.array): An array containing email content after removing the \"Subject:\" prefix.\n",
        "        2. Y (numpy.array): An array indicating whether each email is spam (1) or ham (0).\n",
        "\n",
        "    The function shuffles the input DataFrame to avoid biased results in train/test splits.\n",
        "    It then extracts email content and spam labels, removing the \"Subject:\" prefix from each email.\n",
        "\n",
        "    \"\"\"\n",
        "    # Shuffles the dataset\n",
        "    df = df.sample(frac = 1, ignore_index = True, random_state = 42)\n",
        "    # Removes the \"Subject:\" string, which comprises the first 9 characters of each email. Also, convert it to a numpy array.\n",
        "    X = df.text.apply(lambda x: x[9:]).to_numpy()\n",
        "    # Convert the labels to numpy array\n",
        "    Y = df.spam.to_numpy()\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "9OupIz-uovVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = preprocess_emails(dataframe_emails)"
      ],
      "metadata": {
        "id": "ypYb5pbzoyIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_index = 50\n",
        "print(f\"Email index {email_index}: {X[email_index]}\\n\\n\")\n",
        "print(f\"Class: {Y[email_index]}\")"
      ],
      "metadata": {
        "id": "RzP6xD1Noz77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(X):\n",
        "    \"\"\"\n",
        "    Preprocesses a collection of text data by removing stopwords and punctuation.\n",
        "\n",
        "    Parameters:\n",
        "    - X (str or array-like): The input text data to be processed. If a single string is provided,\n",
        "      it will be converted into a one-element numpy array.\n",
        "\n",
        "    Returns:\n",
        "    - numpy.array: An array of preprocessed text data, where each element represents a document\n",
        "      with stopwords and punctuation removed.\n",
        "\n",
        "    Note:\n",
        "    - The function uses the Natural Language Toolkit (nltk) library for tokenization and stopword removal.\n",
        "    - If the input is a single string, it is converted into a one-element numpy array.\n",
        "    \"\"\"\n",
        "    # Make a set with the stopwords and punctuation\n",
        "    stop = set(stopwords.words('english') + list(string.punctuation))\n",
        "\n",
        "    # The next lines will handle the case where a single email is passed instead of an array of emails.\n",
        "    if isinstance(X, str):\n",
        "        X = np.array([X])\n",
        "\n",
        "    # The result will be stored in a list\n",
        "    X_preprocessed = []\n",
        "\n",
        "    for i, email in enumerate(X):\n",
        "        email = np.array([i.lower() for i in word_tokenize(email) if i.lower() not in stop]).astype(X.dtype)\n",
        "        X_preprocessed.append(email)\n",
        "\n",
        "    if len(X) == 1:\n",
        "        return X_preprocessed[0]\n",
        "    return X_preprocessed"
      ],
      "metadata": {
        "id": "6fA84HYJo1dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function may take a few seconds to run. Usually less than 1 minute.\n",
        "X_treated = preprocess_text(X)"
      ],
      "metadata": {
        "id": "qNOulga-o_Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_index = 989\n",
        "print(f\"Email before preprocessing: {X[email_index]}\")\n",
        "print(f\"Email after preprocessing: {X_treated[email_index]}\")"
      ],
      "metadata": {
        "id": "eohPiu5PpByD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_SIZE = int(0.80*len(X_treated)) # 80% of the samples will be used to train.\n",
        "\n",
        "X_train = X_treated[:TRAIN_SIZE]\n",
        "Y_train = Y[:TRAIN_SIZE]\n",
        "X_test = X_treated[TRAIN_SIZE:]\n",
        "Y_test = Y[TRAIN_SIZE:]"
      ],
      "metadata": {
        "id": "E3DCsCO-piNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Proportion of spam in train dataset: {sum(Y_train == 1)/len(Y_train):.4f}\")\n",
        "print(f\"Proportion of spam in test dataset: {sum(Y_test == 1)/len(Y_test):.4f}\")"
      ],
      "metadata": {
        "id": "IEXsUFjypJYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain the frequency of each word\n",
        "def get_word_frequency(X,Y):\n",
        "    \"\"\"\n",
        "    Calculate the frequency of each word in a set of emails categorized as spam (1) or not spam (0).\n",
        "\n",
        "    Parameters:\n",
        "    - X (numpy.array): Array of emails, where each email is represented as a list of words.\n",
        "    - Y (numpy.array): Array of labels corresponding to each email in X. 1 indicates spam, 0 indicates ham.\n",
        "\n",
        "    Returns:\n",
        "    - word_dict (dict): A dictionary where keys are unique words found in the emails, and values\n",
        "      are dictionaries containing the frequency of each word for spam (1) and not spam (0) emails.\n",
        "    \"\"\"\n",
        "    # Creates an empty dictionary\n",
        "    word_dict = {}\n",
        "\n",
        "    num_emails = len(X)\n",
        "\n",
        "    # Iterates over every processed email and its label\n",
        "    for i in range(num_emails):\n",
        "        # Get the i-th email\n",
        "        email = X[i]\n",
        "        # Get the i-th label. This indicates whether the email is spam or not. 1 = None\n",
        "        # The variable name cls is an abbreviation for class, a reserved word in Python.\n",
        "        cls = Y[i]\n",
        "        # To avoid counting the same word twice in an email, remove duplicates by casting the email as a set\n",
        "        email = set(email)\n",
        "        # Iterates over every distinct word in the email\n",
        "        for word in email:\n",
        "            # If the word is not already in the dictionary, manually add it. Remember that you will start every word count as 1 both in spam and ham\n",
        "            if word not in word_dict.keys():\n",
        "                word_dict[word] = {\"spam\": 1, \"ham\": 1}\n",
        "            # Add one occurrence for that specific word in the key ham if cls == 0 and spam if cls == 1.\n",
        "            if cls == 0:\n",
        "                word_dict[word][\"ham\"] += 1\n",
        "            if cls == 1:\n",
        "                word_dict[word][\"spam\"] += 1\n",
        "\n",
        "    return word_dict"
      ],
      "metadata": {
        "id": "KeN04oobpySP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_output = get_word_frequency([['like','going','river'], ['love', 'deep', 'river'], ['hate','river']], [1,0,0])\n",
        "print(test_output)"
      ],
      "metadata": {
        "id": "8Cy_HWxwe4JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequency = get_word_frequency(X_train,Y_train)"
      ],
      "metadata": {
        "id": "FdXd9y9eqipf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_frequency = {'ham': sum(Y_train == 0), 'spam': sum(Y_train == 1)}"
      ],
      "metadata": {
        "id": "BqauUXYTq09C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_frequency)"
      ],
      "metadata": {
        "id": "mWcCQ83Lq-dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proportion_spam = class_frequency['spam']/(class_frequency['ham'] + class_frequency['spam'])\n",
        "print(f\"The proportion of spam emails in training is: {proportion_spam:.4f}\")"
      ],
      "metadata": {
        "id": "5xL6NntCrlDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prob_word_given_class(word, cls, word_frequency, class_frequency):\n",
        "    \"\"\"\n",
        "    Calculate the conditional probability of a given word occurring in a specific class.\n",
        "\n",
        "    Parameters:\n",
        "    - word (str): The target word for which the probability is calculated.\n",
        "    - cls (str): The class for which the probability is calculated, it may be 'spam' or 'ham'\n",
        "    - word_frequency (dict): The dictionary containing the words frequency.\n",
        "    - class_frequency (dict): The dictionary containing the class frequency.\n",
        "\n",
        "    Returns:\n",
        "    - float: The conditional probability of the given word occurring in the specified class.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the amount of times the word appears with the given class (class is stores in spam variable)\n",
        "    amount_word_and_class = word_frequency[word][cls]\n",
        "    p_word_given_class = amount_word_and_class / class_frequency[cls]\n",
        "\n",
        "    return p_word_given_class"
      ],
      "metadata": {
        "id": "4VccxtrerEM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"P(lottery | spam) = {prob_word_given_class('lottery', cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
        "print(f\"P(lottery | ham) = {prob_word_given_class('lottery', cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
        "print(f\"P(schedule | spam) = {prob_word_given_class('schedule', cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
        "print(f\"P(schedule | ham) = {prob_word_given_class('schedule', cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)}\")"
      ],
      "metadata": {
        "id": "XriM2wrbr6e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prob_email_given_class(treated_email, cls, word_frequency, class_frequency):\n",
        "    \"\"\"\n",
        "    Calculate the probability of an email being of a certain class (e.g., spam or ham) based on treated email content.\n",
        "\n",
        "    Parameters:\n",
        "    - treated_email (list): A list of treated words in the email.\n",
        "    - cls (str): The class label for the email. It can be either 'spam' or 'ham'\n",
        "    - word_frequency (dict): The dictionary containing the words frequency.\n",
        "    - class_frequency (dict): The dictionary containing the class frequency.\n",
        "\n",
        "    Returns:\n",
        "    - float: The probability of the given email belonging to the specified class.\n",
        "    \"\"\"\n",
        "\n",
        "    # prob starts at 1 because it will be updated by multiplying it with the current P(word | class) in every iteration\n",
        "    prob = 1\n",
        "\n",
        "    for word in treated_email:\n",
        "        # Only perform the computation for words that exist in the word frequency dictionary\n",
        "        if word in word_frequency.keys():\n",
        "            # Update the prob by multiplying it with P(word | class). Don't forget to add the word_frequency and class_frequency parameters!\n",
        "            prob *= prob_word_given_class(word, cls, word_frequency, class_frequency)\n",
        "\n",
        "    return prob"
      ],
      "metadata": {
        "id": "1aYto0bfr6s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_email = \"Click here to win a lottery ticket and claim your prize!\"\n",
        "treated_email = preprocess_text(example_email)\n",
        "prob_spam = prob_email_given_class(treated_email, cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "prob_ham = prob_email_given_class(treated_email, cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nP(email | spam) = {prob_spam}\\nP(email | ham) = {prob_ham}\")"
      ],
      "metadata": {
        "id": "_VA9etrlsyp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes(treated_email, word_frequency, class_frequency, return_likelihood = False):\n",
        "    \"\"\"\n",
        "    Naive Bayes classifier for spam detection.\n",
        "\n",
        "    This function calculates the probability of an email being spam (1) or ham (0)\n",
        "    based on the Naive Bayes algorithm. It uses the conditional probabilities of the\n",
        "    treated_email given spam and ham, as well as the prior probabilities of spam and ham\n",
        "    classes. The final decision is made by comparing the calculated probabilities.\n",
        "\n",
        "    Parameters:\n",
        "    - treated_email (list): A preprocessed representation of the input email.\n",
        "    - word_frequency (dict): The dictionary containing the words frequency.\n",
        "    - class_frequency (dict): The dictionary containing the class frequency.\n",
        "        - return_likelihood (bool): If true, it returns the likelihood of both spam and ham.\n",
        "\n",
        "    Returns:\n",
        "    If return_likelihood = False:\n",
        "        - int: 1 if the email is classified as spam, 0 if classified as ham.\n",
        "    If return_likelihood = True:\n",
        "        - tuple: A tuple with the format (spam_likelihood, ham_likelihood)\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute P(email | spam) with the function you defined just above. Don't forget to add the word_frequency and class_frequency parameters!\n",
        "    prob_email_given_spam = prob_email_given_class(treated_email, cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "\n",
        "    # Compute P(email | ham) with the function you defined just above. Don't forget to add the word_frequency and class_frequency parameters!\n",
        "    prob_email_given_ham = prob_email_given_class(treated_email, cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "\n",
        "    # Compute P(spam) using the class_frequency dictionary and using the formula #spam emails / #total emails\n",
        "    p_spam = class_frequency['spam'] / (class_frequency['ham'] + class_frequency['spam'])\n",
        "\n",
        "    # Compute P(ham) using the class_frequency dictionary and using the formula #ham emails / #total emails\n",
        "    p_ham = class_frequency['ham'] / (class_frequency['ham'] + class_frequency['spam'])\n",
        "\n",
        "    # Compute the quantity P(spam) * P(email | spam), let's call it spam_likelihood\n",
        "    spam_likelihood = p_spam * prob_email_given_spam\n",
        "\n",
        "    # Compute the quantity P(ham) * P(email | ham), let's call it ham_likelihood\n",
        "    ham_likelihood = p_ham * prob_email_given_ham\n",
        "\n",
        "\n",
        "    # In case of passing return_likelihood = True, then return the desired tuple\n",
        "    if return_likelihood == True:\n",
        "        return (spam_likelihood, ham_likelihood)\n",
        "\n",
        "    # Compares both values and choose the class corresponding to the higher value\n",
        "    elif spam_likelihood >= ham_likelihood:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "qRxpNc7as2nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_email = \"Click here to win a lottery ticket and claim your prize!\"\n",
        "treated_email = preprocess_text(example_email)\n",
        "\n",
        "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nNaive Bayes predicts this email as: {naive_bayes(treated_email, word_frequency, class_frequency)}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "example_email = \"Our meeting will happen in the main office. Please be there in time.\"\n",
        "treated_email = preprocess_text(example_email)\n",
        "\n",
        "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nNaive Bayes predicts this email as: {naive_bayes(treated_email, word_frequency, class_frequency)}\")"
      ],
      "metadata": {
        "id": "C6nTUhzwuUfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_true_positives(Y_true, Y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the number of true positive instances in binary classification.\n",
        "\n",
        "    Parameters:\n",
        "    - Y_true (list): List of true labels (0 or 1) for each instance.\n",
        "    - Y_pred (list): List of predicted labels (0 or 1) for each instance.\n",
        "\n",
        "    Returns:\n",
        "    - int: Number of true positives, where true label and predicted label are both 1.\n",
        "    \"\"\"\n",
        "    # Both Y_true and Y_pred must match in length.\n",
        "    if len(Y_true) != len(Y_pred):\n",
        "        return \"Number of true labels and predict labels must match!\"\n",
        "    n = len(Y_true)\n",
        "    true_positives = 0\n",
        "    # Iterate over the number of elements in the list\n",
        "    for i in range(n):\n",
        "        # Get the true label for the considered email\n",
        "        true_label_i = Y_true[i]\n",
        "        # Get the predicted (model output) for the considered email\n",
        "        predicted_label_i = Y_pred[i]\n",
        "        # Increase the counter by 1 only if true_label_i = 1 and predicted_label_i = 1 (true positives)\n",
        "        if true_label_i == 1 and predicted_label_i == 1:\n",
        "            true_positives += 1\n",
        "    return true_positives\n",
        "\n",
        "def get_true_negatives(Y_true, Y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the number of true negative instances in binary classification.\n",
        "\n",
        "    Parameters:\n",
        "    - Y_true (list): List of true labels (0 or 1) for each instance.\n",
        "    - Y_pred (list): List of predicted labels (0 or 1) for each instance.\n",
        "\n",
        "    Returns:\n",
        "    - int: Number of true negatives, where true label and predicted label are both 0.\n",
        "    \"\"\"\n",
        "\n",
        "    # Both Y_true and Y_pred must match in length.\n",
        "    if len(Y_true) != len(Y_pred):\n",
        "        return \"Number of true labels and predict labels must match!\"\n",
        "    n = len(Y_true)\n",
        "    true_negatives = 0\n",
        "    # Iterate over the number of elements in the list\n",
        "    for i in range(n):\n",
        "        # Get the true label for the considered email\n",
        "        true_label_i = Y_true[i]\n",
        "        # Get the predicted (model output) for the considered email\n",
        "        predicted_label_i = Y_pred[i]\n",
        "        # Increase the counter by 1 only if true_label_i = 0 and predicted_label_i = 0 (true negatives)\n",
        "        if true_label_i == 0 and predicted_label_i == 0:\n",
        "            true_negatives += 1\n",
        "    return true_negatives\n"
      ],
      "metadata": {
        "id": "DkgQhYmkuVY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get the predictions for the test set:\n",
        "\n",
        "# Create an empty list to store the predictions\n",
        "Y_pred = []\n",
        "\n",
        "# Iterate over every email in the test set\n",
        "for email in X_test:\n",
        "    # Perform prediction\n",
        "    prediction = naive_bayes(email, word_frequency, class_frequency)\n",
        "    # Add it to the list\n",
        "    Y_pred.append(prediction)\n",
        "\n",
        "# Checking if both Y_pred and Y_test (these are the true labels) match in length:\n",
        "print(f\"Y_test and Y_pred matches in length? Answer: {len(Y_pred) == len(Y_test)}\")"
      ],
      "metadata": {
        "id": "CoW4aYC_u_0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of true positives:\n",
        "true_positives = get_true_positives(Y_test, Y_pred)\n",
        "\n",
        "# Get the number of true negatives:\n",
        "true_negatives = get_true_negatives(Y_test, Y_pred)\n",
        "\n",
        "print(f\"The number of true positives is: {true_positives}\\nThe number of true negatives is: {true_negatives}\")\n",
        "\n",
        "# Compute the accuracy by summing true negatives with true positives and dividing it by the total number of elements in the dataset.\n",
        "# Since both Y_pred and Y_test have the same length, it does not matter which one you use.\n",
        "accuracy = (true_positives + true_negatives)/len(Y_test)\n",
        "\n",
        "print(f\"Accuracy is: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "5S3kiYYxvACs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feel free to adjust this email\n",
        "email = \"Please meet me in 2 hours in the main building. I have an important task for you.\"\n",
        "\n",
        "# Preprocess the email\n",
        "treated_email = preprocess_text(email)\n",
        "# Get the prediction, in order to print it nicely, if the output is 1 then the prediction will be written as \"spam\" otherwise \"ham\".\n",
        "prediction = \"spam\" if naive_bayes(treated_email, word_frequency, class_frequency) == 1 else \"ham\"\n",
        "print(f\"The email is: {email}\\nThe model predicts it as {prediction}.\")"
      ],
      "metadata": {
        "id": "WpuXsAWWvCWp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}